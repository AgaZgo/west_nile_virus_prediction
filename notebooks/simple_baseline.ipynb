{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import read_raw_data\n",
    "\n",
    "\n",
    "data = read_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tmax</th>\n",
       "      <th>Tmin</th>\n",
       "      <th>Tavg</th>\n",
       "      <th>Depart</th>\n",
       "      <th>DewPoint</th>\n",
       "      <th>WetBulb</th>\n",
       "      <th>Heat</th>\n",
       "      <th>Cool</th>\n",
       "      <th>...</th>\n",
       "      <th>CodeSum</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Water1</th>\n",
       "      <th>SnowFall</th>\n",
       "      <th>PrecipTotal</th>\n",
       "      <th>StnPressure</th>\n",
       "      <th>SeaLevel</th>\n",
       "      <th>ResultSpeed</th>\n",
       "      <th>ResultDir</th>\n",
       "      <th>AvgSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2</td>\n",
       "      <td>2007-06-13</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>77</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-09-14</td>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>RA BR HZ FU</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>T</td>\n",
       "      <td>29.47</td>\n",
       "      <td>M</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-08-22</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.39</td>\n",
       "      <td>M</td>\n",
       "      <td>4.7</td>\n",
       "      <td>19</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Station        Date  Tmax  Tmin Tavg Depart  DewPoint WetBulb Heat Cool  \\\n",
       "87          2  2007-06-13    86    68   77      M        53      62    0   12   \n",
       "1745        2  2011-09-14    60    48   54      M        45      51   11    0   \n",
       "2067        2  2012-08-22    84    72    M      M        51      61    M    M   \n",
       "\n",
       "      ...      CodeSum Depth Water1 SnowFall PrecipTotal StnPressure SeaLevel  \\\n",
       "87    ...                  M      M        M        0.00           M        M   \n",
       "1745  ...  RA BR HZ FU     M      M        M           T       29.47        M   \n",
       "2067  ...                  M      M        M        0.00       29.39        M   \n",
       "\n",
       "     ResultSpeed ResultDir  AvgSpeed  \n",
       "87           7.0         5         M  \n",
       "1745         6.0        32         M  \n",
       "2067         4.7        19         M  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['weather'][data['weather']['AvgSpeed']=='M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict AvgSpeeed using ResultSpeed and ResultDir\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train = data['weather'][data['weather']['AvgSpeed']!='M'][['ResultSpeed', 'ResultDir', 'AvgSpeed']].astype(float)\n",
    "y_train = X_train.pop('AvgSpeed')\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "X_test = data['weather'][data['weather']['AvgSpeed']=='M'][['ResultSpeed', 'ResultDir']]\n",
    "missing_value_predictions = lr_model.predict(X_test).round(1)\n",
    "\n",
    "m_index = data['weather'][data['weather']['AvgSpeed']=='M'].index\n",
    "data['weather'].loc[m_index, 'AvgSpeed'] = missing_value_predictions\n",
    "\n",
    "data['weather']['AvgSpeed'] = data['weather']['AvgSpeed'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import clean_weather\n",
    "\n",
    "\n",
    "data['weather'] = clean_weather(data['weather'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline]  (step 1 of 3) Processing functiontransformer-1, total=   0.0s\n",
      "[Pipeline]  (step 2 of 3) Processing monthspeciestraptransformer, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing functiontransformer-2, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "from src.data import build_data_preprocessing_pipeline\n",
    "\n",
    "\n",
    "# build preprocessing pipeline\n",
    "data_preprocessing_pipeline = build_data_preprocessing_pipeline()\n",
    "\n",
    "# preprocess train and test data\n",
    "data['train'] = data_preprocessing_pipeline.fit_transform(data['train'])\n",
    "data['test'] = data_preprocessing_pipeline.transform(data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features import SpeciesEncoder\n",
    "\n",
    "\n",
    "species_oh_encoder = SpeciesEncoder()\n",
    "data['train'] = species_oh_encoder.fit_transform(data['train'])\n",
    "data['test'] = species_oh_encoder.transform(data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train'] = data['train'][['Date', 'Latitude', 'Longitude', 'Dayofyear',\n",
    "       'Species_CULEX PIPIENS', 'Species_CULEX PIPIENS/RESTUANS',\n",
    "       'Species_CULEX RESTUANS', 'WnvPresent']]\n",
    "data['test'] = data['test'][['Date', 'Id', 'Latitude', 'Longitude', 'Dayofyear',\n",
    "       'Species_CULEX PIPIENS', 'Species_CULEX PIPIENS/RESTUANS',\n",
    "       'Species_CULEX RESTUANS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train'] = data['train'].merge(data['weather'], on='Date')\n",
    "data['test'] = data['test'].merge(data['weather'], on='Date')\n",
    "data['train'].drop('Date', axis=1, inplace=True)\n",
    "data['test'].drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0545\n"
     ]
    }
   ],
   "source": [
    "X_train = data['train'].copy()\n",
    "y_train = X_train.pop('WnvPresent')\n",
    "\n",
    "print(y_train.mean().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours, RandomUnderSampler, NeighbourhoodCleaningRule\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n",
    "\n",
    "from src.evaluate import evaluate\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    'lr': LogisticRegression(),\n",
    "    # 'svc': SVC(probability=True),\n",
    "    # 'rand_forest': RandomForestClassifier(),\n",
    "    'lgbm_unb': LGBMClassifier(is_unbalance=True),\n",
    "    'lgbm': LGBMClassifier(is_unbalance=False),\n",
    "    # 'xgb': XGBClassifier(),\n",
    "    # 'bag_lr': BaggingClassifier(LogisticRegression(), n_estimators=100, max_samples=0.8, max_features=0.5)\n",
    "}\n",
    "\n",
    "def run_one_clf(clf):\n",
    "\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        # ('smote', SMOTE(sampling_strategy=0.2)),\n",
    "        ('adasyn', ADASYN(sampling_strategy=0.3)),\n",
    "        # ('tomek', TomekLinks()),\n",
    "        ('enn', EditedNearestNeighbours()),\n",
    "        ('clf', clf)\n",
    "    ]\n",
    "\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3)\n",
    "\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, scoring='roc_auc', cv=cv)\n",
    "\n",
    "    val_score = cv_results['test_score'].mean().round(4)\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    public_score, private_score = evaluate(pipeline, data['test'], X_train.columns.to_list())\n",
    "    \n",
    "    return private_score, public_score, str(val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aga/repos/west_nile_virus/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/aga/.kaggle/kaggle.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.79M/1.79M [00:01<00:00, 1.16MB/s]\n",
      "\u001b[32m2024-09-28 13:51:25.119\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.evaluate\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m56\u001b[0m - \u001b[34m\u001b[1mFile pushed to Kaggle API\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 - Bad Request - Submission not allowed:  Your team has used its daily Submission allowance (5) today, please try again tomorrow UTC (11 hours from now).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-28 13:51:27.018\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.evaluate\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m73\u001b[0m - \u001b[34m\u001b[1mKaggle scores logged to mlfmlow.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2269, number of negative: 6454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4009\n",
      "[LightGBM] [Info] Number of data points in the train set: 8723, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.260117 -> initscore=-1.045361\n",
      "[LightGBM] [Info] Start training from score -1.045361\n",
      "[LightGBM] [Info] Number of positive: 2140, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4165\n",
      "[LightGBM] [Info] Number of data points in the train set: 8559, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.250029 -> initscore=-1.098457\n",
      "[LightGBM] [Info] Start training from score -1.098457\n",
      "[LightGBM] [Info] Number of positive: 2176, number of negative: 6471\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3984\n",
      "[LightGBM] [Info] Number of data points in the train set: 8647, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.251648 -> initscore=-1.089842\n",
      "[LightGBM] [Info] Start training from score -1.089842\n",
      "[LightGBM] [Info] Number of positive: 2195, number of negative: 6480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3976\n",
      "[LightGBM] [Info] Number of data points in the train set: 8675, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.253026 -> initscore=-1.082538\n",
      "[LightGBM] [Info] Start training from score -1.082538\n",
      "[LightGBM] [Info] Number of positive: 2174, number of negative: 6467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3984\n",
      "[LightGBM] [Info] Number of data points in the train set: 8641, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.251591 -> initscore=-1.090144\n",
      "[LightGBM] [Info] Start training from score -1.090144\n",
      "[LightGBM] [Info] Number of positive: 2169, number of negative: 6446\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4003\n",
      "[LightGBM] [Info] Number of data points in the train set: 8615, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.251770 -> initscore=-1.089194\n",
      "[LightGBM] [Info] Start training from score -1.089194\n",
      "[LightGBM] [Info] Number of positive: 2147, number of negative: 6476\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3979\n",
      "[LightGBM] [Info] Number of data points in the train set: 8623, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.248985 -> initscore=-1.104032\n",
      "[LightGBM] [Info] Start training from score -1.104032\n",
      "[LightGBM] [Info] Number of positive: 2153, number of negative: 6475\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3929\n",
      "[LightGBM] [Info] Number of data points in the train set: 8628, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249536 -> initscore=-1.101086\n",
      "[LightGBM] [Info] Start training from score -1.101086\n",
      "[LightGBM] [Info] Number of positive: 2148, number of negative: 6425\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3938\n",
      "[LightGBM] [Info] Number of data points in the train set: 8573, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.250554 -> initscore=-1.095659\n",
      "[LightGBM] [Info] Start training from score -1.095659\n",
      "[LightGBM] [Info] Number of positive: 2166, number of negative: 6457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4018\n",
      "[LightGBM] [Info] Number of data points in the train set: 8623, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.251189 -> initscore=-1.092283\n",
      "[LightGBM] [Info] Start training from score -1.092283\n",
      "[LightGBM] [Info] Number of positive: 2166, number of negative: 6480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3997\n",
      "[LightGBM] [Info] Number of data points in the train set: 8646, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.250520 -> initscore=-1.095838\n",
      "[LightGBM] [Info] Start training from score -1.095838\n",
      "[LightGBM] [Info] Number of positive: 2152, number of negative: 6469\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4156\n",
      "[LightGBM] [Info] Number of data points in the train set: 8621, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249623 -> initscore=-1.100624\n",
      "[LightGBM] [Info] Start training from score -1.100624\n",
      "[LightGBM] [Info] Number of positive: 2159, number of negative: 6478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3998\n",
      "[LightGBM] [Info] Number of data points in the train set: 8637, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249971 -> initscore=-1.098767\n",
      "[LightGBM] [Info] Start training from score -1.098767\n",
      "[LightGBM] [Info] Number of positive: 2171, number of negative: 6455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4163\n",
      "[LightGBM] [Info] Number of data points in the train set: 8626, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.251681 -> initscore=-1.089667\n",
      "[LightGBM] [Info] Start training from score -1.089667\n",
      "[LightGBM] [Info] Number of positive: 2167, number of negative: 6412\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3964\n",
      "[LightGBM] [Info] Number of data points in the train set: 8579, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.252594 -> initscore=-1.084828\n",
      "[LightGBM] [Info] Start training from score -1.084828\n",
      "[LightGBM] [Info] Number of positive: 2693, number of negative: 8041\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4011\n",
      "[LightGBM] [Info] Number of data points in the train set: 10734, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.250885 -> initscore=-1.093898\n",
      "[LightGBM] [Info] Start training from score -1.093898\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/aga/.kaggle/kaggle.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.81M/1.81M [00:01<00:00, 1.08MB/s]\n",
      "\u001b[32m2024-09-28 13:51:46.869\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.evaluate\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m56\u001b[0m - \u001b[34m\u001b[1mFile pushed to Kaggle API\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 - Bad Request - Submission not allowed:  Your team has used its daily Submission allowance (5) today, please try again tomorrow UTC (11 hours from now).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-28 13:51:49.232\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.evaluate\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m73\u001b[0m - \u001b[34m\u001b[1mKaggle scores logged to mlfmlow.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2166, number of negative: 6417\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4003\n",
      "[LightGBM] [Info] Number of data points in the train set: 8583, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.252359 -> initscore=-1.086069\n",
      "[LightGBM] [Info] Start training from score -1.086069\n",
      "[LightGBM] [Info] Number of positive: 2144, number of negative: 6453\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3998\n",
      "[LightGBM] [Info] Number of data points in the train set: 8597, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249389 -> initscore=-1.101872\n",
      "[LightGBM] [Info] Start training from score -1.101872\n",
      "[LightGBM] [Info] Number of positive: 2161, number of negative: 6529\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4122\n",
      "[LightGBM] [Info] Number of data points in the train set: 8690, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.248677 -> initscore=-1.105683\n",
      "[LightGBM] [Info] Start training from score -1.105683\n",
      "[LightGBM] [Info] Number of positive: 2172, number of negative: 6445\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3971\n",
      "[LightGBM] [Info] Number of data points in the train set: 8617, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.252060 -> initscore=-1.087656\n",
      "[LightGBM] [Info] Start training from score -1.087656\n",
      "[LightGBM] [Info] Number of positive: 2186, number of negative: 6466\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4309\n",
      "[LightGBM] [Info] Number of data points in the train set: 8652, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.252658 -> initscore=-1.084484\n",
      "[LightGBM] [Info] Start training from score -1.084484\n",
      "[LightGBM] [Info] Number of positive: 2166, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3981\n",
      "[LightGBM] [Info] Number of data points in the train set: 8610, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.251568 -> initscore=-1.090267\n",
      "[LightGBM] [Info] Start training from score -1.090267\n",
      "[LightGBM] [Info] Number of positive: 2149, number of negative: 6433\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3995\n",
      "[LightGBM] [Info] Number of data points in the train set: 8582, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.250408 -> initscore=-1.096438\n",
      "[LightGBM] [Info] Start training from score -1.096438\n",
      "[LightGBM] [Info] Number of positive: 2180, number of negative: 6485\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4118\n",
      "[LightGBM] [Info] Number of data points in the train set: 8665, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.251587 -> initscore=-1.090167\n",
      "[LightGBM] [Info] Start training from score -1.090167\n",
      "[LightGBM] [Info] Number of positive: 2194, number of negative: 6421\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3936\n",
      "[LightGBM] [Info] Number of data points in the train set: 8615, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.254672 -> initscore=-1.073848\n",
      "[LightGBM] [Info] Start training from score -1.073848\n",
      "[LightGBM] [Info] Number of positive: 2170, number of negative: 6506\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3988\n",
      "[LightGBM] [Info] Number of data points in the train set: 8676, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.250115 -> initscore=-1.097998\n",
      "[LightGBM] [Info] Start training from score -1.097998\n",
      "[LightGBM] [Info] Number of positive: 2192, number of negative: 6406\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3992\n",
      "[LightGBM] [Info] Number of data points in the train set: 8598, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.254943 -> initscore=-1.072421\n",
      "[LightGBM] [Info] Start training from score -1.072421\n",
      "[LightGBM] [Info] Number of positive: 2135, number of negative: 6461\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3995\n",
      "[LightGBM] [Info] Number of data points in the train set: 8596, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.248371 -> initscore=-1.107317\n",
      "[LightGBM] [Info] Start training from score -1.107317\n",
      "[LightGBM] [Info] Number of positive: 2125, number of negative: 6484\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3979\n",
      "[LightGBM] [Info] Number of data points in the train set: 8609, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.246835 -> initscore=-1.115566\n",
      "[LightGBM] [Info] Start training from score -1.115566\n",
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6481\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3968\n",
      "[LightGBM] [Info] Number of data points in the train set: 8658, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.251444 -> initscore=-1.090927\n",
      "[LightGBM] [Info] Start training from score -1.090927\n",
      "[LightGBM] [Info] Number of positive: 2168, number of negative: 6432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4169\n",
      "[LightGBM] [Info] Number of data points in the train set: 8600, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.252093 -> initscore=-1.087480\n",
      "[LightGBM] [Info] Start training from score -1.087480\n",
      "[LightGBM] [Info] Number of positive: 2693, number of negative: 8030\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3995\n",
      "[LightGBM] [Info] Number of data points in the train set: 10723, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.251142 -> initscore=-1.092529\n",
      "[LightGBM] [Info] Start training from score -1.092529\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/aga/.kaggle/kaggle.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.81M/1.81M [00:01<00:00, 1.22MB/s]\n",
      "\u001b[32m2024-09-28 13:52:06.691\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.evaluate\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m56\u001b[0m - \u001b[34m\u001b[1mFile pushed to Kaggle API\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 - Bad Request - Submission not allowed:  Your team has used its daily Submission allowance (5) today, please try again tomorrow UTC (11 hours from now).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-28 13:52:08.748\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.evaluate\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m73\u001b[0m - \u001b[34m\u001b[1mKaggle scores logged to mlfmlow.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(columns=['private_score', 'public_score', 'val_score'])\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    results_df.loc[name] = run_one_clf(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.69362</td>\n",
       "      <td>0.70306</td>\n",
       "      <td>0.7636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm_unb</th>\n",
       "      <td>0.69362</td>\n",
       "      <td>0.70306</td>\n",
       "      <td>0.8234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>0.69362</td>\n",
       "      <td>0.70306</td>\n",
       "      <td>0.8209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         private_score public_score val_score\n",
       "lr             0.69362      0.70306    0.7636\n",
       "lgbm_unb       0.69362      0.70306    0.8234\n",
       "lgbm           0.69362      0.70306    0.8209"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.63004</td>\n",
       "      <td>0.64238</td>\n",
       "      <td>0.7658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm_unb</th>\n",
       "      <td>0.71196</td>\n",
       "      <td>0.72452</td>\n",
       "      <td>0.8219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>0.71501</td>\n",
       "      <td>0.72811</td>\n",
       "      <td>0.8191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         private_score public_score val_score\n",
       "lr             0.63004      0.64238    0.7658\n",
       "lgbm_unb       0.71196      0.72452    0.8219\n",
       "lgbm           0.71501      0.72811    0.8191"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.64199</td>\n",
       "      <td>0.65169</td>\n",
       "      <td>0.7669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm_unb</th>\n",
       "      <td>0.72579</td>\n",
       "      <td>0.73338</td>\n",
       "      <td>0.8247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>0.70161</td>\n",
       "      <td>0.70123</td>\n",
       "      <td>0.8213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         private_score public_score val_score\n",
       "lr             0.64199      0.65169    0.7669\n",
       "lgbm_unb       0.72579      0.73338    0.8247\n",
       "lgbm           0.70161      0.70123    0.8213"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.63936</td>\n",
       "      <td>0.64902</td>\n",
       "      <td>0.7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm_unb</th>\n",
       "      <td>0.73591</td>\n",
       "      <td>0.74634</td>\n",
       "      <td>0.8237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>0.68611</td>\n",
       "      <td>0.70312</td>\n",
       "      <td>0.8248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         private_score public_score val_score\n",
       "lr             0.63936      0.64902    0.7662\n",
       "lgbm_unb       0.73591      0.74634    0.8237\n",
       "lgbm           0.68611      0.70312    0.8248"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.65514</td>\n",
       "      <td>0.66740</td>\n",
       "      <td>0.7633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm_unb</th>\n",
       "      <td>0.71874</td>\n",
       "      <td>0.73564</td>\n",
       "      <td>0.8276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>0.70479</td>\n",
       "      <td>0.72474</td>\n",
       "      <td>0.8296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         private_score public_score val_score\n",
       "lr             0.65514      0.66740    0.7633\n",
       "lgbm_unb       0.71874      0.73564    0.8276\n",
       "lgbm           0.70479      0.72474    0.8296"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.65697</td>\n",
       "      <td>0.66909</td>\n",
       "      <td>0.7623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_lr</th>\n",
       "      <td>0.67855</td>\n",
       "      <td>0.68860</td>\n",
       "      <td>0.7461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       private_score public_score val_score\n",
       "lr           0.65697      0.66909    0.7623\n",
       "bag_lr       0.67855      0.68860    0.7461"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.65697</td>\n",
       "      <td>0.66909</td>\n",
       "      <td>0.7629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_lr</th>\n",
       "      <td>0.68191</td>\n",
       "      <td>0.69084</td>\n",
       "      <td>0.7457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       private_score public_score val_score\n",
       "lr           0.65697      0.66909    0.7629\n",
       "bag_lr       0.68191      0.69084    0.7457"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.65697</td>\n",
       "      <td>0.66909</td>\n",
       "      <td>0.7627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rand_forest</th>\n",
       "      <td>0.66412</td>\n",
       "      <td>0.69276</td>\n",
       "      <td>0.7692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>0.72206</td>\n",
       "      <td>0.73312</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0.70955</td>\n",
       "      <td>0.73028</td>\n",
       "      <td>0.8275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_lr</th>\n",
       "      <td>0.67325</td>\n",
       "      <td>0.68345</td>\n",
       "      <td>0.7526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            private_score public_score val_score\n",
       "lr                0.65697      0.66909    0.7627\n",
       "rand_forest       0.66412      0.69276    0.7692\n",
       "lgbm              0.72206      0.73312     0.833\n",
       "xgb               0.70955      0.73028    0.8275\n",
       "bag_lr            0.67325      0.68345    0.7526"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.65697</td>\n",
       "      <td>0.66909</td>\n",
       "      <td>0.7644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rand_forest</th>\n",
       "      <td>0.67081</td>\n",
       "      <td>0.69972</td>\n",
       "      <td>0.7678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>0.72206</td>\n",
       "      <td>0.73312</td>\n",
       "      <td>0.8326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0.70955</td>\n",
       "      <td>0.73028</td>\n",
       "      <td>0.8236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_lr</th>\n",
       "      <td>0.65703</td>\n",
       "      <td>0.67004</td>\n",
       "      <td>0.7575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            private_score public_score val_score\n",
       "lr                0.65697      0.66909    0.7644\n",
       "rand_forest       0.67081      0.69972    0.7678\n",
       "lgbm              0.72206      0.73312    0.8326\n",
       "xgb               0.70955      0.73028    0.8236\n",
       "bag_lr            0.65703      0.67004    0.7575"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.65697</td>\n",
       "      <td>0.66909</td>\n",
       "      <td>0.7637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rand_forest</th>\n",
       "      <td>0.67031</td>\n",
       "      <td>0.70529</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>0.72206</td>\n",
       "      <td>0.73312</td>\n",
       "      <td>0.8331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0.70955</td>\n",
       "      <td>0.73028</td>\n",
       "      <td>0.8274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            private_score public_score val_score\n",
       "lr                0.65697      0.66909    0.7637\n",
       "rand_forest       0.67031      0.70529     0.764\n",
       "lgbm              0.72206      0.73312    0.8331\n",
       "xgb               0.70955      0.73028    0.8274"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_fraction=0.6\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.65697</td>\n",
       "      <td>0.66909</td>\n",
       "      <td>0.7621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rand_forest</th>\n",
       "      <td>0.67211</td>\n",
       "      <td>0.71738</td>\n",
       "      <td>0.7726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>0.70962</td>\n",
       "      <td>0.72971</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0.70955</td>\n",
       "      <td>0.73028</td>\n",
       "      <td>0.8291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            private_score public_score val_score\n",
       "lr                0.65697      0.66909    0.7621\n",
       "rand_forest       0.67211      0.71738    0.7726\n",
       "lgbm              0.70962      0.72971     0.832\n",
       "xgb               0.70955      0.73028    0.8291"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is_unbalanced in lgbm\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.60649</td>\n",
       "      <td>0.60403</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rand_forest</th>\n",
       "      <td>0.64914</td>\n",
       "      <td>0.68921</td>\n",
       "      <td>0.7675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>0.71065</td>\n",
       "      <td>0.73095</td>\n",
       "      <td>0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0.70955</td>\n",
       "      <td>0.73028</td>\n",
       "      <td>0.8297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            private_score public_score val_score\n",
       "lr                0.60649      0.60403     0.742\n",
       "rand_forest       0.64914      0.68921    0.7675\n",
       "lgbm              0.71065      0.73095    0.8312\n",
       "xgb               0.70955      0.73028    0.8297"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no scaling\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.65697</td>\n",
       "      <td>0.66909</td>\n",
       "      <td>0.7634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rand_forest</th>\n",
       "      <td>0.64848</td>\n",
       "      <td>0.68473</td>\n",
       "      <td>0.7687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>0.70962</td>\n",
       "      <td>0.72971</td>\n",
       "      <td>0.8308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0.70955</td>\n",
       "      <td>0.73028</td>\n",
       "      <td>0.8268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            private_score public_score val_score\n",
       "lr                0.65697      0.66909    0.7634\n",
       "rand_forest       0.64848      0.68473    0.7687\n",
       "lgbm              0.70962      0.72971    0.8308\n",
       "xgb               0.70955      0.73028    0.8268"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with scaling\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': -1,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_leaves': 31,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0,\n",
       " 'is_unbalance': True}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(is_unbalance=True)\n",
    "lgbm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
